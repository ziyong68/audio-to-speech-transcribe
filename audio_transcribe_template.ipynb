{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For MacOS\n",
    "# pip install -U openai-whisper\n",
    "# /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n",
    "# cd ~\n",
    "# export PATH=/opt/homebrew/bin:$PATH\n",
    "# brew install ffmpeg\n",
    "\n",
    "# os.environ['PATH'] += os.pathsep + \"/opt/homebrew/bin\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Windows\n",
    "# winget install --id Gyan.FFmpeg -e\n",
    "# Restart terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env;C:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env;C:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env\\\\Library\\\\bin;C:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env\\\\Scripts;C:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env\\\\bin;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v11.4\\\\bin;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v11.4\\\\libnvvp;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\Windows\\\\System32\\\\OpenSSH;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\WINDOWS\\\\System32\\\\OpenSSH;C:\\\\Program Files\\\\NVIDIA Corporation\\\\Nsight Compute 2021.2.1;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\WINDOWS\\\\System32\\\\OpenSSH;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA app\\\\NvDLISR;C:\\\\Users\\\\brian\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\cudnn-11.4-windows-x64-v8.2.4.15\\\\cuda\\\\bin;C:\\\\Users\\\\brian\\\\AppData\\\\Local\\\\GitHubDesktop\\\\bin;C:\\\\ProgramData\\\\Anaconda3\\\\Library\\\\bin;C:\\\\ProgramData\\\\Anaconda3\\\\Scripts;C:\\\\ProgramData\\\\Anaconda3\\\\condabin;C:\\\\Users\\\\brian\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\brian\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\cudnn-11.4-windows-x64-v8.2.4.15\\\\cuda\\\\bin;C:\\\\Users\\\\brian\\\\AppData\\\\Local\\\\GitHubDesktop\\\\bin;C:\\\\ProgramData\\\\Anaconda3\\\\Library\\\\bin\\\\conda.bat;C:\\\\ProgramData\\\\Anaconda3\\\\Scripts\\\\conda.exe;C:\\\\ProgramData\\\\Anaconda3\\\\condabin\\\\conda.bat;C:\\\\Users\\\\brian\\\\AppData\\\\Local\\\\Microsoft\\\\WinGet\\\\Packages\\\\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\\\\ffmpeg-8.0.1-full_build\\\\bin;.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os; os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ffmpeg' in os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env\\\\python312.zip',\n",
       " 'c:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env\\\\DLLs',\n",
       " 'c:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env\\\\Lib',\n",
       " 'c:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env',\n",
       " '',\n",
       " 'c:\\\\Users\\\\brian\\\\.conda\\\\envs\\\\whisper_env\\\\Lib\\\\site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys; sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call packges\n",
    "import whisper\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\brian\\\\audio-to-speech-transcribe'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder\n",
    "os.makedirs(\"./output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planning to process ./001_Khenpo_Tsultrim_Intro_with_Vietnamese.mp3:\n"
     ]
    }
   ],
   "source": [
    "# Detect mp3 files\n",
    "file_list = []\n",
    "\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "    if filename.endswith(\".mp3\"):\n",
    "        print('planning to process ' + \"./\" + filename + \":\")\n",
    "        file_list.append(filename)\n",
    "# Using this trick, you can loop through files in current working directory and transcribe all of them in a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001_Khenpo_Tsultrim_Intro_with_Vietnamese.mp3']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively\n",
    "# Using list comprehension achieves the same thing\n",
    "file_list = [filename for filename in os.listdir(os.getcwd()) if filename.endswith(\".mp3\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001_Khenpo_Tsultrim_Intro_with_Vietnamese.mp3']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiny.en',\n",
       " 'tiny',\n",
       " 'base.en',\n",
       " 'base',\n",
       " 'small.en',\n",
       " 'small',\n",
       " 'medium.en',\n",
       " 'medium',\n",
       " 'large-v1',\n",
       " 'large-v2',\n",
       " 'large-v3',\n",
       " 'large',\n",
       " 'large-v3-turbo',\n",
       " 'turbo']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiny.en',\n",
       " 'tiny',\n",
       " 'base.en',\n",
       " 'base',\n",
       " 'small.en',\n",
       " 'small',\n",
       " 'medium.en',\n",
       " 'medium',\n",
       " 'large-v1',\n",
       " 'large-v2',\n",
       " 'large-v3',\n",
       " 'large',\n",
       " 'large-v3-turbo',\n",
       " 'turbo']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a model instance\n",
    "model = whisper.load_model(\"turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\brian\\\\audio-to-speech-transcribe'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os; os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\AppData\\Local\\Microsoft\\WinGet\\Packages\\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\\ffmpeg-8.0.1-full_build\\bin\\ffmpeg.EXE\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "print(shutil.which('ffmpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./001_Khenpo_Tsultrim_Intro_with_Vietnamese.mp3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brian\\.conda\\envs\\whisper_env\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "transcription_list = []\n",
    "\n",
    "for filename in file_list:\n",
    "    print('processing ' + \"./\" + filename + \".\")\n",
    "    transcription = model.transcribe(\"./\" + filename)\n",
    "    print('finished ' + \"./\" + filename + \".\")\n",
    "    transcription_list.append(transcription)\n",
    "    transcribed = transcription['text'].replace(\". \", \".\\n\")\n",
    "    filename = filename.replace('mp3', 'txt')\n",
    "    with open(f\"./output/{filename}\", \"w\") as text_file:\n",
    "        text_file.write(f\"{transcribed}\\nTHE END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 1000 characters to glimpse\n",
    "for result in transcription_list:\n",
    "    print(result[\"text\"][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add a line break for each sentence for readibility and save text file\n",
    "# for filename, result in zip(file_list, transcription_list):\n",
    "#     transcribed = result['text'].replace(\". \", \".\\n\")\n",
    "#     filename = filename.replace('mp3', 'txt')\n",
    "#     with open(f\"./output/{filename}\", \"w\") as text_file:\n",
    "#         text_file.write(f\"{transcribed}\\nTHE END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 token ~= 3/4 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
